##############################################################################
############################ OPENSHIFT API SERVER ############################
##############################################################################
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alerts-openshift-apiserver
  namespace: openshift-apiserver
spec:
  groups:
    - name: alerts-openshift-apiserver
      rules:
        - alert: openshift_apiserver_podcount
          annotations:
            description: Es muss zumindest 1 Pod da sein
            summary: Apiserver nicht mehr erreichbar.
          expr: 'absent(sum(up{job="api"})>=1)'
          for: 10m
          labels:
            severity: "critical"
            type: "internal"
        - alert: openshift_apiserver_memory_saturation
          annotations:
            summary: Openshift Apiserver Memory Issue
            description: |
              Openshift Apiserver {{`{{$labels.pod}}`}} hat in den letzten 10 Minuten durchschnittlich mehr als 250% der Memory Requests benötigt. Es ist sehr wahrscheinlich, dass hier ein Problem besteht.
          expr: |
            (sum(
            avg_over_time(container_memory_working_set_bytes{namespace="openshift-apiserver", container!="", image!=""}[10m])
            * on(namespace,pod)
            group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{ namespace="openshift-apiserver", workload="apiserver", workload_type="deployment"}
            ) by (pod)
            /sum(
            kube_pod_container_resource_requests{job="kube-state-metrics",namespace="openshift-apiserver", resource="memory"}
            * on(namespace,pod)
            group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{namespace="openshift-apiserver",workload="apiserver",workload_type="deployment"}
            ) by (pod)) > 2.5
          for: 10m
          labels:
            severity: "critical"
            type: "internal"
---
##############################################################################
######################### OPENSHIFT KUBE API SERVER ##########################
##############################################################################
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alerts-openshift-kube-apiserver
  namespace: openshift-kube-apiserver
spec:
  groups:
    - name: alerts-openshift-kube-apiserver
      rules:
        - alert: kubeapiserver_podcount
          annotations:
            description: Es muss zumindest 1 Pod da sein
            summary: Kube-Apiserver nicht mehr erreichbar.
          expr: 'absent(sum(up{job="apiserver"})>=1)'
          for: 10m
          labels:
            severity: "critical"
            type: "internal"
        - alert: kubeapiserver_memory_saturation
          annotations:
            summary: Openshift Kube-Apiserver Memory Issue
            description: |
              Openshift Kube-Apiserver {{`{{$labels.pod}}`}} hat in den letzten 10 Minuten durchschnittlich mehr als 1000% der Memory Requests benötigt. Es ist sehr wahrscheinlich, dass hier ein Problem besteht.
          expr: |
            (sum(
            avg_over_time(container_memory_working_set_bytes{namespace="openshift-kube-apiserver", container="kube-apiserver", image!=""}[10m])
            ) by (pod)
            /sum(
            kube_pod_container_resource_requests{job="kube-state-metrics",namespace="openshift-kube-apiserver", resource="memory",container="kube-apiserver"}
            ) by (pod)) > 10
          for: 10m
          labels:
            severity: "critical"
            type: "internal"
---
##############################################################################
################################### NODES ####################################
##############################################################################
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alerts-ocp-nodes
  namespace: openshift-monitoring
spec:
  groups:
    - name: alerts-ocp-nodes
      rules:
        - alert: node_unready
          annotations:
            description: Node Issue
            summary: 'Node {{`{{$labels.node}}`}} ist seit 30 Minuten NICHT mehr im Status Ready.'
          expr: 'kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0'
          for: 30m
          labels:
            severity: "critical"
            type: "internal"