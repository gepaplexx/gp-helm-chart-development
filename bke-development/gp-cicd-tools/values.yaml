####################
#### VARIABLES #####
####################
argo_workflows_db: &argo_workflows_db "argo_workflows"
argo_workflows_db_secret: &argo_workflows_db_secret "gepaplexx-cicd-tools-postgresql"
argo_workflows_db_host: &argo_workflows_db_host "argo-workflows-postgres"

####################
## SEALED SECRETS ##
####################
sealedSecret:
  postgresql:
    postgres-password: ""
    password: ""
    username: ""

####################
##  ARGO  EVENTS  ##
####################
argo_events:
  enabled: true
  fullnameOverride: argo-events
  openshift: true
  crds:
    install: false
  controller:
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi
  configs:
    jetstream:
      versions:
      # Die hier angegebenen Versionen werden in die "argo-events-controller-manager" ConfigMap geschrieben.
      # Das ist die Voraussetzung dafür, dass die "EventBus" Ressource den EventBus mit der angegebenen Version starten kann.
        - version: "2.9.14"
          natsImage: docker.io/nats:2.9.14
          metricsExporterImage: docker.io/natsio/prometheus-nats-exporter:0.10.1
          configReloaderImage: docker.io/natsio/nats-server-config-reloader:0.10.1
          startCommand: /nats-server
      # Default-Latest Version wie im Sub-Chart normalerweise konfiguriert.
        - version: "latest"
          natsImage: docker.io/nats:latest
          metricsExporterImage: docker.io/natsio/prometheus-nats-exporter:latest
          configReloaderImage: docker.io/natsio/nats-server-config-reloader:latest
          startCommand: /nats-server

####################
## ARGO WORFKLOWS ##
####################
argo_workflows:
  enabled: true
  fullnameOverride: argo-workflows
  crds:
    install: true
    keep: false

  images:
    pullPolicy: IfNotPresent

  rbac:
    sudoGroup: Gepaplexx
    clusterscoped:
      developerGroup: Gepardec
      enabled: false
    defaultRead: true
    clientSecret: "" # SealedsecretEncrypted ClientSecret
    clientId: "argo-workflows"

  server:
    extraArgs:
      - "--auth-mode=sso"
      - "--auth-mode=client"
    extraEnv:
      - name: "SSO_DELEGATE_RBAC_TO_NAMESPACE"
        value: "true"
    # sso configuration:
    sso:
      issuer: "https://sso.apps.clustername.example.com/realms/internal"
      redirectUrl: "https://workflows.example.com/oauth2/callback"
      clientSecret:
        name: argo-workflows-sso
        key: client-secret
      clientId:
        name: argo-workflows-sso
        key: client-id
      rbac:
        enabled: true
    ingress:
      enabled: true
      hosts:
        - workflows.example.com
      ingressClassName: "openshift-default"
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt
      tls:
        - hosts:
            - workflows.example.com
          secretName: workflows.example.com-tls
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi

  mainContainer:
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 4Gi

  controller:
    parallelism: 10 # 10 workflows can be executed at the same time cluster-wide
    namespaceParallelism: 5 # only 5 workflows per namespace can be executed in parallel
    nodeStatusOffLoad: false
    workflowDefaults:
      spec:
        ttlStrategy:
            secondsAfterCompletion: 3600 # delete workflows after 1 hour. they are still available in the archive
        metrics:
          prometheus:
            - name: duration_gauge
              help: "Duration gauge by name"
              labels:
                - key: application
                  value: "{{ workflow.parameters.reponame }}"
                - key: branch
                  value: "{{ workflow.parameters.branch }}"
                - key: status
                  value: "{{ workflow.status }}"
              gauge:
                realtime: true                  # This metric will be emitted in real time. For more info see: docs/metrics.md
                value: "{{workflow.duration}}"  # Use {{workflow.duration}} in workflow-level and {{duration}} in template-level
            - name: result_count
              help: "Workflow Result Counter"
              labels:
                - key: application
                  value: "{{ workflow.parameters.reponame }}"
                - key: branch
                  value: "{{ workflow.parameters.branch }}"
                - key: status
                  value: "{{ workflow.status }}"
              counter:
                value: 1
    workflowRestrictions:
      templateReferencing: Strict # only workflows using workflowTemplateRef will be executed
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi

    metricsConfig:
      enabled: true
      metricsTTL: 2h # Metriken werden nach 2 Stunden vom Workflow Controller Endpunkt gelöscht.
    serviceMonitor:
      enabled: true

    persistence:
      archive: true
      nodeStatusOffLoad: true # if true node status is only saved to the persistence DB to avoid the 1MB limit in etcd
      archiveTTL: 120d
      connectionPool:
        maxIdleConns: 50
      postgresql:
        host: *argo_workflows_db_host
        port: 5432
        database: *argo_workflows_db
        tableName: argo_workflows
        userNameSecret:
          name: *argo_workflows_db_secret
          key: username
        passwordSecret:
          name: *argo_workflows_db_secret
          key: password

  archive:
    enabled: true
    secretkey: ""
  useDefaultArtifactRepo: true
  artifactRepository:
    archiveLogs: true
    s3:
      accessKeySecret:
        name: minio-artifact-repository
        key: accesskey
      secretKeySecret:
        name: minio-artifact-repository
        key: secretkey
      insecure: true
      bucket: argo-workflows
      endpoint: minio-artifact-repository.gepaplexx-cicd-tools:9000

  workflow:
    serviceAccount:
      create: true
      name: operate-workflow-sa

#####################
## Workflows Minio ##
#####################
minio:
  auth:
    existingSecret: "minio-artifact-repository"
  fullnameOverride: minio-artifact-repository
  replicas: 1
  persistence:
    size: 25Gi
  resources:
    requests:
      memory: 2Gi #default 4Gi bei 500Gi persistent storage. Sollte mit weniger auch auskommen.
  provisioning:
    enabled: true
    buckets:
    - name: argo-workflows
      purge: false
      policy: none
  serviceAccount:
    name: minio



####################
##    ARGO  CD    ##
####################
argocd:
  enabled: true
  route:
    hostname: "argocd.example.com"
  applicationset:
    resources:
      limits:
        cpu: "1"
        memory: 1Gi
      requests:
        cpu: 250m
        memory: 512Mi
  controller:
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi
  dex:
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi
  redis:
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 250m
        memory: 128Mi
  repo:
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi
  server:
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi
  rbac:
    defaultPolicy: ''
    policies:
      - 'p, role:gepardec-admin, applications, *, *, allow'
      - 'p, role:gepardec-admin, repositories, *, *, allow'
      - 'p, role:gepardec-admin, projects, *, *, allow'
      - 'g, Gepaplexx, role:admin'
      - 'g, Gepardec, role:gepardec-admin'

######################
##    Postgresql    ##
######################
postgresql:
  enabled: true
  fullnameOverride: *argo_workflows_db_host
  service:
    ports:
      postgresql: 5432
  auth:
    username: argo_workflow
    database: *argo_workflows_db
    password: ""
    existingSecret: *argo_workflows_db_secret
  primary:
    podSecurityContext:
      enabled: false
    containerSecurityContext:
      enabled: false
